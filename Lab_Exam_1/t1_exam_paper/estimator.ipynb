{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ankit/anaconda/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.5\n",
      "  return f(*args, **kwds)\n",
      "/Users/ankit/anaconda/lib/python3.5/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import math\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNNRegressor(tf.estimator.Estimator):\n",
    "    def __init__(self, feature_columns, outputs, hidden_units=2, **kwargs):\n",
    "        super().__init__(model_fn=self._model_fn, params={\n",
    "            'feature_columns': feature_columns,\n",
    "            'hidden_units': hidden_units,\n",
    "            'outputs': outputs\n",
    "        },**kwargs)\n",
    "    \n",
    "    def _model_fn(self, features, labels, mode, params):\n",
    "        inp = tf.feature_column.input_layer(features, params['feature_columns'])\n",
    "        h = tf.layers.dense(inp, units=params['hidden_units'], activation=tf.nn.relu,name='hidden')\n",
    "        out = tf.layers.dense(h, units=params['outputs'], activation=None,name=\"output\")\n",
    "\n",
    "        if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "            predictions = {\n",
    "                'logits': out\n",
    "            }\n",
    "            return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
    "\n",
    "        # Compute loss.\n",
    "        loss = tf.losses.mean_squared_error(labels=labels,predictions=out)\n",
    "        # Compute evaluation metrics.\n",
    "        precision = tf.metrics.precision(labels=labels,\n",
    "                                       predictions=out,\n",
    "                                       name='pre_op')\n",
    "        recall = tf.metrics.recall(labels=labels,\n",
    "                                       predictions=out,\n",
    "                                       name='rec_op')\n",
    "        metrics = {}\n",
    "        #metrics = {'precision': precision,'recall':recall}\n",
    "        #tf.summary.scalar('precision', precision[1])\n",
    "        #tf.summary.scalar('recall', recall[1])\n",
    "\n",
    "        if mode == tf.estimator.ModeKeys.EVAL:\n",
    "            return tf.estimator.EstimatorSpec(\n",
    "                mode, loss=loss, eval_metric_ops=metrics)\n",
    "\n",
    "        # Create training op.\n",
    "        assert mode == tf.estimator.ModeKeys.TRAIN\n",
    "\n",
    "        optimizer = tf.train.AdagradOptimizer(learning_rate=0.1)\n",
    "        train_op = optimizer.minimize(loss, global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)\n",
    "\n",
    "    def get_layer_params(self, layer_name):\n",
    "        return self.get_variable_value('{}/kernel'.format(layer_name)), self.get_variable_value('{}/bias'.format(layer_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn_y1():\n",
    "    d = tf.contrib.data.CsvDataset('algebra.csv',[tf.float32]*4)\n",
    "    d = d.batch(32).map(lambda x1,x2,y1,y2:({\"x1\":x1,\"x2\":x2},tf.transpose(tf.stack([y1]))))\n",
    "    return d\n",
    "\n",
    "def input_fn_y2():\n",
    "    d = tf.contrib.data.CsvDataset('algebra.csv',[tf.float32]*4)\n",
    "    d = d.batch(32).map(lambda x1,x2,y1,y2:({\"x1\":x1,\"x2\":x2},tf.transpose(tf.stack([y2]))))\n",
    "    return d\n",
    "\n",
    "def input_fn_both():\n",
    "    d = tf.contrib.data.CsvDataset('algebra.csv',[tf.float32]*4)\n",
    "    d = d.batch(32).map(lambda x1,x2,y1,y2:({\"x1\":x1,\"x2\":x2},tf.transpose(tf.stack([y1,y2]))))\n",
    "    return d\n",
    "\n",
    "def train_data(input_fn):\n",
    "    count = 0\n",
    "    for i in input_fn():\n",
    "        count += 1\n",
    "    return lambda: input_fn().take(math.floor(count*0.85))\n",
    "    \n",
    "def test_data(input_fn):\n",
    "    count = 0\n",
    "    for i in input_fn():\n",
    "        count += 1\n",
    "    return lambda: input_fn().skip(math.ceil(count*0.85))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models():\n",
    "    d_y1.train(train_data(input_fn_y1))\n",
    "    d_y2.train(train_data(input_fn_y2))\n",
    "    d_both.train(train_data(input_fn_both))\n",
    "    d_both_large.train(train_data(input_fn_both))\n",
    "\n",
    "def eval_models():\n",
    "    print(\"y1:\")\n",
    "    print(d_y1.evaluate(input_fn=test_data(input_fn_y1)))\n",
    "    print(\"y2:\")\n",
    "    print(d_y2.evaluate(input_fn=test_data(input_fn_y2)))\n",
    "    print(\"Both:\")\n",
    "    print(d_both.evaluate(input_fn=test_data(input_zfn_both)))\n",
    "    print(\"Both(Large):\")\n",
    "    print(d_both_large.evaluate(input_fn=test_data(input_fn_both)))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/60/h5y4q3zs4fl_wkw_007jnhp80000gn/T/tmpxje888sf\n",
      "INFO:tensorflow:Using config: {'_task_id': 0, '_train_distribute': None, '_service': None, '_global_id_in_cluster': 0, '_session_config': None, '_save_checkpoints_steps': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_device_fn': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x1c24c13c50>, '_model_dir': '/var/folders/60/h5y4q3zs4fl_wkw_007jnhp80000gn/T/tmpxje888sf', '_num_ps_replicas': 0, '_task_type': 'worker', '_tf_random_seed': None, '_master': '', '_is_chief': True, '_evaluation_master': '', '_keep_checkpoint_every_n_hours': 10000, '_keep_checkpoint_max': 5, '_num_worker_replicas': 1, '_log_step_count_steps': 100}\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/60/h5y4q3zs4fl_wkw_007jnhp80000gn/T/tmp1iyg6cst\n",
      "INFO:tensorflow:Using config: {'_task_id': 0, '_train_distribute': None, '_service': None, '_global_id_in_cluster': 0, '_session_config': None, '_save_checkpoints_steps': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_device_fn': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x1c24c13eb8>, '_model_dir': '/var/folders/60/h5y4q3zs4fl_wkw_007jnhp80000gn/T/tmp1iyg6cst', '_num_ps_replicas': 0, '_task_type': 'worker', '_tf_random_seed': None, '_master': '', '_is_chief': True, '_evaluation_master': '', '_keep_checkpoint_every_n_hours': 10000, '_keep_checkpoint_max': 5, '_num_worker_replicas': 1, '_log_step_count_steps': 100}\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/60/h5y4q3zs4fl_wkw_007jnhp80000gn/T/tmpw7d8o221\n",
      "INFO:tensorflow:Using config: {'_task_id': 0, '_train_distribute': None, '_service': None, '_global_id_in_cluster': 0, '_session_config': None, '_save_checkpoints_steps': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_device_fn': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x1c24c13c88>, '_model_dir': '/var/folders/60/h5y4q3zs4fl_wkw_007jnhp80000gn/T/tmpw7d8o221', '_num_ps_replicas': 0, '_task_type': 'worker', '_tf_random_seed': None, '_master': '', '_is_chief': True, '_evaluation_master': '', '_keep_checkpoint_every_n_hours': 10000, '_keep_checkpoint_max': 5, '_num_worker_replicas': 1, '_log_step_count_steps': 100}\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/60/h5y4q3zs4fl_wkw_007jnhp80000gn/T/tmp6egk3p3u\n",
      "INFO:tensorflow:Using config: {'_task_id': 0, '_train_distribute': None, '_service': None, '_global_id_in_cluster': 0, '_session_config': None, '_save_checkpoints_steps': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_device_fn': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x1c24c13dd8>, '_model_dir': '/var/folders/60/h5y4q3zs4fl_wkw_007jnhp80000gn/T/tmp6egk3p3u', '_num_ps_replicas': 0, '_task_type': 'worker', '_tf_random_seed': None, '_master': '', '_is_chief': True, '_evaluation_master': '', '_keep_checkpoint_every_n_hours': 10000, '_keep_checkpoint_max': 5, '_num_worker_replicas': 1, '_log_step_count_steps': 100}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /var/folders/60/h5y4q3zs4fl_wkw_007jnhp80000gn/T/tmpxje888sf/model.ckpt.\n",
      "INFO:tensorflow:loss = 132.17993, step = 1\n",
      "INFO:tensorflow:global_step/sec: 644.222\n",
      "INFO:tensorflow:loss = 78.83429, step = 101 (0.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 670.754\n",
      "INFO:tensorflow:loss = 116.25026, step = 201 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 683.546\n",
      "INFO:tensorflow:loss = 82.49382, step = 301 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 835.158\n",
      "INFO:tensorflow:loss = 136.01367, step = 401 (0.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 793.776\n",
      "INFO:tensorflow:loss = 101.723206, step = 501 (0.126 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 531 into /var/folders/60/h5y4q3zs4fl_wkw_007jnhp80000gn/T/tmpxje888sf/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 95.03043.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /var/folders/60/h5y4q3zs4fl_wkw_007jnhp80000gn/T/tmp1iyg6cst/model.ckpt.\n",
      "INFO:tensorflow:loss = 3.646422, step = 1\n",
      "INFO:tensorflow:global_step/sec: 371.778\n",
      "INFO:tensorflow:loss = 15.22304, step = 101 (0.272 sec)\n",
      "INFO:tensorflow:global_step/sec: 409.207\n",
      "INFO:tensorflow:loss = 26.419653, step = 201 (0.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 470.112\n",
      "INFO:tensorflow:loss = 15.504949, step = 301 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 814.969\n",
      "INFO:tensorflow:loss = 45.901108, step = 401 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 853.994\n",
      "INFO:tensorflow:loss = 881.8006, step = 501 (0.117 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 531 into /var/folders/60/h5y4q3zs4fl_wkw_007jnhp80000gn/T/tmp1iyg6cst/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 23.279099.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /var/folders/60/h5y4q3zs4fl_wkw_007jnhp80000gn/T/tmpw7d8o221/model.ckpt.\n",
      "INFO:tensorflow:loss = 45.874496, step = 1\n",
      "INFO:tensorflow:global_step/sec: 669.246\n",
      "INFO:tensorflow:loss = 21.567055, step = 101 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 787.221\n",
      "INFO:tensorflow:loss = 24.117628, step = 201 (0.127 sec)\n",
      "INFO:tensorflow:global_step/sec: 768.675\n",
      "INFO:tensorflow:loss = 21.325495, step = 301 (0.130 sec)\n",
      "INFO:tensorflow:global_step/sec: 582.683\n",
      "INFO:tensorflow:loss = 30.739552, step = 401 (0.173 sec)\n",
      "INFO:tensorflow:global_step/sec: 502.778\n",
      "INFO:tensorflow:loss = 380.0291, step = 501 (0.197 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 531 into /var/folders/60/h5y4q3zs4fl_wkw_007jnhp80000gn/T/tmpw7d8o221/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 13.021328.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /var/folders/60/h5y4q3zs4fl_wkw_007jnhp80000gn/T/tmp6egk3p3u/model.ckpt.\n",
      "INFO:tensorflow:loss = 51.999092, step = 1\n",
      "INFO:tensorflow:global_step/sec: 581.987\n",
      "INFO:tensorflow:loss = 6.209327, step = 101 (0.175 sec)\n",
      "INFO:tensorflow:global_step/sec: 638.399\n",
      "INFO:tensorflow:loss = 19.89261, step = 201 (0.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 797.314\n",
      "INFO:tensorflow:loss = 59.10896, step = 301 (0.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 731.327\n",
      "INFO:tensorflow:loss = 54.07652, step = 401 (0.138 sec)\n",
      "INFO:tensorflow:global_step/sec: 693.385\n",
      "INFO:tensorflow:loss = 232.66359, step = 501 (0.143 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 531 into /var/folders/60/h5y4q3zs4fl_wkw_007jnhp80000gn/T/tmp6egk3p3u/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 49.98412.\n",
      "y1:\n",
      "{'global_step': 531, 'loss': 109.250145}\n",
      "y2:\n",
      "{'global_step': 531, 'loss': 1123.5438}\n",
      "Both:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'input_zfn_both' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-12e459850df8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtrain_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_verbosity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWARN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0meval_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_verbosity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINFO\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-afd5950ec4d6>\u001b[0m in \u001b[0;36meval_models\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_y2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn_y2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Both:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_both\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_zfn_both\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Both(Large):\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_both_large\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn_both\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'input_zfn_both' is not defined"
     ]
    }
   ],
   "source": [
    "feat_cols = [tf.feature_column.numeric_column('x1'), tf.feature_column.numeric_column('x2')]\n",
    "d_y1 = DNNRegressor(feat_cols,outputs=1)\n",
    "d_y2 = DNNRegressor(feat_cols,outputs=1)\n",
    "d_both = DNNRegressor(feat_cols,outputs=2)\n",
    "d_both_large = DNNRegressor(feat_cols,hidden_units=100,outputs=2)\n",
    "\n",
    "train_models()\n",
    "tf.logging.set_verbosity(tf.logging.WARN)    \n",
    "eval_models()\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "(w1,w2), (b1,b2) = d_y1.get_layer_params('hidden') \n",
    "(w0),(b0,) = d_y1.get_layer_params('output')\n",
    "w0 = w0.T[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
